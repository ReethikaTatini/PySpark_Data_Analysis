{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kbgQSpNVp-0G"
   },
   "source": [
    "**Intall Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHlG66VW4aox",
    "outputId": "e7779327-fbb9-401f-b275-4e17cddc9fbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=600ebb46f9ab556f73a5f14be14c662ed2014f8f5f705d7b86c70865b091dee7\n",
      "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
      "Successfully built pyspark\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.5.0\n",
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkchsBGkubET"
   },
   "source": [
    "**Intialize finspark and create Spark Session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tCZNi59E6zMR"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"Amazon_Reviews_Analysis\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NoMotBgIB6Fr"
   },
   "source": [
    "**Mount Google drive for path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vij-XRtu6zN8",
    "outputId": "e6f855f8-a27b-45ad-9d5e-7b00a4176447"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount your Google Drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OBR0oGEqCLQy"
   },
   "source": [
    "**Read csv and convert it into dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zKKNMWiCorK",
    "outputId": "ac7c8228-0967-4d58-cef1-068d28cbc10b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+----------+------+---+------+\n",
      "|user_id|recipe_id|      date|rating|  u|     i|\n",
      "+-------+---------+----------+------+---+------+\n",
      "|  76535|    33627|2005-02-15|   4.0|  5|177317|\n",
      "| 160497|    75307|2005-10-24|   4.0| 23|170785|\n",
      "| 930021|   100961|2008-11-30|   4.0| 31|165555|\n",
      "|  58439|   154105|2007-03-24|   4.0| 44|177453|\n",
      "| 628951|    14525|2008-02-16|   5.0| 45|142367|\n",
      "+-------+---------+----------+------+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_path = '/content/drive/My Drive/Colab Notebooks/interactions_validation.csv'\n",
    "reviews_df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
    "reviews_df.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iNVVKH2NCQai"
   },
   "source": [
    "**Find least, most and longest ratings and format date column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ox2fBSpfCowi",
    "outputId": "0029b64e-1105-4bec-96cf-a64bfef3244f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|recipe_id|count|\n",
      "+---------+-----+\n",
      "|   301798|    1|\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----+\n",
      "|recipe_id|count|\n",
      "+---------+-----+\n",
      "|    83928|    4|\n",
      "+---------+-----+\n",
      "\n",
      "+---------+-----------------+\n",
      "|recipe_id|max_review_length|\n",
      "+---------+-----------------+\n",
      "|   241491|           178263|\n",
      "+---------+-----------------+\n",
      "\n",
      "+-------+---------+----------+------+---+------+----------+\n",
      "|user_id|recipe_id|      date|rating|  u|     i|  new_date|\n",
      "+-------+---------+----------+------+---+------+----------+\n",
      "|  76535|    33627|2005-02-15|   4.0|  5|177317|2005-02-15|\n",
      "| 160497|    75307|2005-10-24|   4.0| 23|170785|2005-10-24|\n",
      "| 930021|   100961|2008-11-30|   4.0| 31|165555|2008-11-30|\n",
      "|  58439|   154105|2007-03-24|   4.0| 44|177453|2007-03-24|\n",
      "| 628951|    14525|2008-02-16|   5.0| 45|142367|2008-02-16|\n",
      "+-------+---------+----------+------+---+------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+---------+----------+------+---+------+----------+\n",
      "|user_id|recipe_id|      date|rating|  u|     i|  new_date|\n",
      "+-------+---------+----------+------+---+------+----------+\n",
      "| 628951|    14525|2008-02-16|   5.0| 45|142367|2008-02-16|\n",
      "|  52476|   132931|2005-09-08|   5.0| 47|162220|2005-09-08|\n",
      "|  37722|   378255|2009-07-05|   5.0| 48|174635|2009-07-05|\n",
      "| 495793|   359362|2009-12-30|   5.0| 64|175382|2009-12-30|\n",
      "| 724516|   365093|2011-03-03|   5.0| 71|176938|2011-03-03|\n",
      "+-------+---------+----------+------+---+------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, length, to_date, date_format\n",
    "\n",
    "# Group by 'recipe_id' and count the number of ratings\n",
    "ratings_count = reviews_df.groupBy('recipe_id').count()\n",
    "\n",
    "# Sort the DataFrame by count in ascending order to get the least rated items\n",
    "least_rated_items = ratings_count.sort(col('count')).limit(1)\n",
    "\n",
    "# Sort the DataFrame by count in descending order to get the most rated items\n",
    "most_rated_items = ratings_count.sort(col('count').desc()).limit(1)\n",
    "least_rated_items.show(5)\n",
    "most_rated_items.show(5)\n",
    "\n",
    "# Calculate the length of reviews ('i') for each item ('recipe_id')\n",
    "reviews_length = reviews_df.groupBy('recipe_id').agg({'i': 'max'}).withColumnRenamed('max(i)', 'max_review_length')\n",
    "\n",
    "# Find the item with the maximum review length\n",
    "longest_review_item = reviews_length.sort(col('max_review_length').desc()).limit(1)\n",
    "longest_review_item.show(5)\n",
    "\n",
    "# Transformation: Change date format\n",
    "reviews_df = reviews_df.withColumn(\"new_date\", to_date(col(\"date\"), \"MM-dd-yyyy\"))\n",
    "reviews_df.show(5)\n",
    "\n",
    "# DataFrame Operation example (Filtering)\n",
    "desired_operation = reviews_df.filter(col(\"rating\") > 4)\n",
    "desired_operation.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BRCgAdY-C2Wk"
   },
   "source": [
    "**Convert PySpark DataFrame into Pandas DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "523Hikt8PdSV"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#converting PySpark DataFrame into Pandas DataFrame\n",
    "pandas_df = reviews_df.toPandas()\n",
    "\n",
    "# Convert 'date' column to datetime format\n",
    "pandas_df['date'] = pd.to_datetime(pandas_df['date'])\n",
    "\n",
    "# Convert the 'date' column to MM-DD-YYYY format\n",
    "pandas_df['date'] = pandas_df['date'].dt.strftime('%m-%d-%Y')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpK51A0_C-ob"
   },
   "source": [
    "**Insert DataFrame into a database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1CU0qBFPPdUa"
   },
   "outputs": [],
   "source": [
    "#Storing DataFrame into database using sqlite\n",
    "import sqlite3\n",
    "\n",
    "sqlite_db = 'example.db'\n",
    "\n",
    "# Create a connection to the SQLite database file\n",
    "conn = sqlite3.connect(sqlite_db)\n",
    "\n",
    "# Write Pandas DataFrame to SQLite database file\n",
    "pandas_df.to_sql('reviews', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OoVBTc8iDIR7"
   },
   "source": [
    "**Convert file into parquet file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Yr6csURErW3n"
   },
   "outputs": [],
   "source": [
    "output_parquet_path = \"/content/drive/My Drive/Colab Notebooks/validation_parquet_file\"  # Replace with your desired output path\n",
    "reviews_df.write.parquet(output_parquet_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TFgbGG-iDPls"
   },
   "source": [
    "**Stop the Spark Session**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BKn_Wu3PtGRj"
   },
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gwTE3hbTtGTj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
